{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCPVLufrSvDX"
   },
   "source": [
    "Installing the nessicary libraries and setting up the envorenment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8YpB3kMdUeG",
    "outputId": "ca218108-017f-4bf1-964b-64b46e17c109"
   },
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXlsUp-6IrnW"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5IGJOEkIstZ"
   },
   "outputs": [],
   "source": [
    "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uL_8mKuIxES"
   },
   "outputs": [],
   "source": [
    "!tar xf spark-3.0.2-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyU3ytp7Jsn3"
   },
   "outputs": [],
   "source": [
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQUHlpTCJLr4"
   },
   "outputs": [],
   "source": [
    "#seting up the environment to run Pyspark\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awrlhmlbJXmC"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3aaLsO2F9yF"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORou3AbHdOZc"
   },
   "outputs": [],
   "source": [
    "#Creating a session\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id = 'AWS_ACCESS_KEY',\n",
    "    aws_secret_access_key = 'AWS_SECRET_KEY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp34T2A-dhfU"
   },
   "outputs": [],
   "source": [
    "#connecting to Amazon s3 Bucket\n",
    "s3 = session.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCMuCw9zdk48"
   },
   "outputs": [],
   "source": [
    "bucket = s3.Bucket('BUCKET NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ynkRxFCdmwM",
    "outputId": "08a83024-370c-4469-c987-f9f975a0906e"
   },
   "outputs": [],
   "source": [
    "#checking bucket for all objects\n",
    "for item in bucket.objects.all():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrhDZ9JHdo0U"
   },
   "outputs": [],
   "source": [
    "#creating the client to get the JSON files\n",
    "client = boto3.client('s3',\n",
    "    aws_access_key_id = 'AWS_ACCESS_KEY',\n",
    "    aws_secret_access_key = 'AWS_SECRET_KEY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xhc-RdAdq1E"
   },
   "outputs": [],
   "source": [
    "obj_1 = client.get_object(Bucket = 'BUCKET NAME', Key = '1.jl')\n",
    "obj_2 = client.get_object(Bucket = 'BUCKET NAME', Key = '2.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FApaOo3mdurC"
   },
   "outputs": [],
   "source": [
    "item1 = obj_1['Body'].read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxpQaINjgZrE"
   },
   "outputs": [],
   "source": [
    "item1 = item1.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7g0rLglw1DT",
    "outputId": "8ccdc334-761f-49ff-e0ea-542e9f710581"
   },
   "outputs": [],
   "source": [
    "len(item1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoYrU1qeh2iU",
    "outputId": "30bcd6e8-8c58-4508-ba9d-a3be8d69901b"
   },
   "outputs": [],
   "source": [
    "#converting strings into json files\n",
    "json_list = []\n",
    "\n",
    "for item in split:\n",
    "  try:\n",
    "    obj = json.loads(item)\n",
    "    json_list.append(obj)\n",
    "  except json.decoder.JSONDecodeError:\n",
    "      print(item, \" String could not be converted to JSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VR4s9tEPEZzT",
    "outputId": "75b3a6c3-4891-4c09-90c4-77d5dbf7c49f"
   },
   "outputs": [],
   "source": [
    "len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SV8TrFMezsGA"
   },
   "outputs": [],
   "source": [
    "#returning values for category_id and quantity\n",
    "\n",
    "for i in item1:\n",
    "  if i == 'category_id':\n",
    "    print(item1[i])\n",
    "  if i == 'quantity':\n",
    "    print(item1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iAmDR7u0p06"
   },
   "outputs": [],
   "source": [
    "#returnign values for category_id and quantity\n",
    "agg_dict = {}\n",
    "\n",
    "for item in json_list:\n",
    "  for i in item:\n",
    "    if i == 'item_id':\n",
    "      key = item[i]\n",
    "    if i == 'category_id':\n",
    "      category = item[i]\n",
    "    if i == 'quantity':\n",
    "      qty = item[i]\n",
    "      agg_dict[key] = [category,qty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzidW9Ici9za",
    "outputId": "527fe7c0-fffd-4ac6-b1df-ec2eda24aad0"
   },
   "outputs": [],
   "source": [
    "#spot check agg_dict\n",
    "item1 = json_list[7000]\n",
    "item1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzmHgvdhGXie",
    "outputId": "dcb87260-c524-46f4-9e32-7a189078b6ef"
   },
   "outputs": [],
   "source": [
    "agg_dict['29358354']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0A_X-ZcNaM5"
   },
   "outputs": [],
   "source": [
    "#returnign values for category_id and quantity list for pyspark df\n",
    "agg_list = []\n",
    "\n",
    "for item in json_list:\n",
    "  obj_dict = {}\n",
    "  for i in item:\n",
    "    if i == 'item_id':\n",
    "      item_id = item[i]\n",
    "      obj_dict['item_id'] = item_id\n",
    "    if i == 'category_id':\n",
    "      category = item[i]\n",
    "      obj_dict['category'] = category\n",
    "    if i == 'quantity':\n",
    "      qty = item[i]\n",
    "      obj_dict['quantity'] = qty\n",
    "  agg_list.append(obj_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UsG3u1VU7VG"
   },
   "source": [
    "creating functions for the steps of the cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pM2nRg0SThSm"
   },
   "outputs": [],
   "source": [
    "#Method for API to JSON object from multi JASON request string \n",
    "def apiObjectToJSON(obj):\n",
    "  objStr = obj['Body'].read().decode()\n",
    "  split = test.split(\"\\n\")\n",
    "\n",
    "  json_list = []\n",
    "\n",
    "  for item in split:\n",
    "    try:\n",
    "      obj = json.loads(item)\n",
    "      json_list.append(obj)\n",
    "    except json.decoder.JSONDecodeError:\n",
    "      print(item, \" String could not be converted to JSON\")\n",
    "\n",
    "  return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5ih5uNIU2zl"
   },
   "outputs": [],
   "source": [
    "#Method for JSON to dictonary with item_id, category_id, quantity\n",
    "def jsonListToDict(json_list):\n",
    "  agg_list = []\n",
    "\n",
    "  for item in json_list:\n",
    "    obj_dict = {}\n",
    "    for i in item:\n",
    "      if i == 'item_id':\n",
    "        item_id = item[i]\n",
    "        obj_dict['item_id'] = item_id\n",
    "      if i == 'category_id':\n",
    "        category = item[i]\n",
    "        obj_dict['category'] = category\n",
    "      if i == 'quantity':\n",
    "        qty = item[i]\n",
    "        obj_dict['quantity'] = qty\n",
    "    agg_list.append(obj_dict)\n",
    "    \n",
    "  return agg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_7rql5NVDsy",
    "outputId": "5cebb599-d304-4563-a017-eb5c64d73d3d"
   },
   "outputs": [],
   "source": [
    "#used cleaning methods on second sample\n",
    "json_obj_2 = apiObjectToJSON(obj_2)\n",
    "\n",
    "agg_list_obj2 = jsonListToDict(json_obj_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWD8LZ-dHsb2"
   },
   "outputs": [],
   "source": [
    "#converting dictionary into spark sql dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PWhTNepLt9H",
    "outputId": "570b41dd-3ed2-4be5-bc14-0de11580670a"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(agg_list)\n",
    "print(df.schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJLgoG0yMD33"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"json_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-jjOZQOPXaI"
   },
   "outputs": [],
   "source": [
    "sql_agg = spark.sql(\"SELECT category AS category_id, SUM(quantity) AS total FROM json_1 GROUP BY category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsOfnebMPoDP",
    "outputId": "e9da594c-5199-4645-8e8d-2778970911ff"
   },
   "outputs": [],
   "source": [
    "sql_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ95bu9nQ8Ep",
    "outputId": "09fc5b5e-fd2e-4d4b-b4b0-9f94ac7fb242"
   },
   "outputs": [],
   "source": [
    "#test calibration\n",
    "sql_agg_test = spark.sql(\"SELECT category AS category_id, SUM(quantity) AS total FROM json_1 WHERE category = '976760_3788935' GROUP BY category\")\n",
    "sql_agg_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JHNpMutRaLK"
   },
   "outputs": [],
   "source": [
    "sql_agg.coalesce(1).write.format('json').save('/1-total.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lY7LIJL5R2qr",
    "outputId": "65e06ecc-e78d-4693-95a9-b8836ef1de96"
   },
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(agg_list_obj22)\n",
    "print(df.schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V81KAyFbWAiG"
   },
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"json_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cDYiiPgWKZG",
    "outputId": "de06c8bd-0fbe-4e87-e852-b2cb671b5905"
   },
   "outputs": [],
   "source": [
    "sql_agg2 = spark.sql(\"SELECT category AS category_id, SUM(quantity) AS total FROM json_2 GROUP BY category\")\n",
    "sql_agg2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN8Stc7tWPMV",
    "outputId": "d6fd0309-3e8c-4d0d-aba7-588ace73428c"
   },
   "outputs": [],
   "source": [
    "#2test calibration\n",
    "sql_agg_test2 = spark.sql(\"SELECT category AS category_id, SUM(quantity) AS total FROM json_2 WHERE category = '976760_3788935_2118445' GROUP BY category\")\n",
    "sql_agg_test2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5C97rDPWe_u"
   },
   "outputs": [],
   "source": [
    "sql_agg2.coalesce(1).write.format('json').save('/2-total.json')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Coding_Challenge_Amber_Toro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
